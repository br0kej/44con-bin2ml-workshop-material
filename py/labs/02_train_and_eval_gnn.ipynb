{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate your own GNN\n",
    "\n",
    "To make this straightforwad and efficent, I have created a few helper classes that do a lot of the heavy lifting for you! \n",
    "\n",
    "There is a `GNNTrainer` class which provides a nice interface to train your first Graph Neural Network (GNN) and then there is a `GNNEvaultor` class which provides a nice interface to evaluate your model! \n",
    "\n",
    "\n",
    "**Note**: Running this on a laptop *without* a GPU is not the most performant. Depending on your hardware, the loading of the data may taken 5 or so minutes and the training (once you execute the cell `trainer.train()` will take about 10 minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bin2mlpy.training.train import GNNTrainer\n",
    "from bin2mlpy.eval.eval import SearchPoolGNNEvaluator, NDayGNNEvaluator\n",
    "from bin2mlpy.training.gnn import GCN, GraphConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_PKL = \"../train.pkl\" # The path to the processed train data\n",
    "EVAL_DATA_PKL = \"../test.pkl\" # The path to the processed test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GNNTrainer(model_cls=GCN, \n",
    "                     training_dataset_pickle=TRAINING_DATA_PKL,\n",
    "                     evaluation_dataset_pickle=EVAL_DATA_PKL,\n",
    "                     num_samples_per_epoch=100000,\n",
    "                     num_training_epochs=50,\n",
    "                     hidden_dimension_size=128,\n",
    "                     learning_rate=0.0001,\n",
    "                     batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your GNN\n",
    "\n",
    "We are going to use the `GNNEvaluator` class to get an idea of our performant our GNN is. This class takes a collection of input data and then creates *search pools*. A search pool is created by first selecting a function you want to search (the query function) and then creating a single positive pair whereby the query function is paired with another example of the same function and then creating 100 negative pairs whereby the query function is paired with a random other function. \n",
    "\n",
    "Each pair within each search pool is then embedded using our model and then the cosine distance between each is calculated. These similiarity scores are then ranked with the highest first. The higher the rank, the more similiar our model thinks the pairs are! We then use the metrics MRR@10 and R@1 to give us an idea of how good the model is performing. For both of these metrics, 1 is perfect performance!\n",
    "\n",
    "**Note:** Due to the difficulty of the cross-architecture function search task and the limited hardware available (no GPU) restricting how long we can train these models for, do not expect amazing performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = SearchPoolGNNEvaluator(model=trainer.model, \n",
    "                         eval_data=trainer.eval_dataset, \n",
    "                         num_search_pools=50, \n",
    "                         search_pool_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRR @ 10: 0.42270001769065857\n",
    "Recall @ 1: 0.2857142984867096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about N-day detection performance?!\n",
    "\n",
    "There is another evaluator included called `NDayGNNEvaluator`. This evaluator works by searching two `openssl` samples taken from real devices which a collection of known vulnerable sample versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = NDayGNNEvaluator(model=trainer.model, eval_data_dir=\"../../data/vuln-eval/graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.tplink_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.netgear_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch Experimentation/After Hours\n",
    "\n",
    "There are several ways we could improve this performance:\n",
    "\n",
    "1) Increase the training time - This can be done in two different ways in our case. The first is increasing the `num_training_epochs` parameters in the `GNNTrainer`. This will increase the number of times the model processes a single pass through the data. The second is increasing the `num_samples_per_epoch` parameters within the `GNNTrainer`. This determines how many samples are sampled from the dataset as a whole to make the data for a given epoch. I would suggest doing *both* of these. I would increase `num_samples_per_epoch` to `250000` and `num_training_epochs` to 250.\n",
    "2) Increase the batch size - When formulating the problem in the way we have, contrastive learning - learning by comparing two things together and using the output as the loss, a very easy way to boost performance is by increasing the batch size. The batch size determines how many samples are put into the model at once. What this really means in our case though is when we increase the batch size, we are increasing the number of negative samples that can be associated with each positive. This gives the model a better signal of what is good and what is bad!\n",
    "3) Change the GNN layer used within the model - The model is currently using the `GCN` layer described on the online website. We could chagne this to the `GraphConv` layer which has been proven to improve performance usually. I have created a equalivant model using the `GraphConv` layer called `GraphConvNet`. Try this out and see how it effects performance.\n",
    "4) Change the learning rate - The learning rate determines how small or large the adjustments the optimiser can make given the loss. Experiment with lowering the loss to a smaller value and observe the loss values printed by the trainer class. It is likely you will see smaller but consistently lower loss values. This is because the model is making smaller but more precise adjustments. That being said, a very small learning rate will make the training process take a very long time. Experiment with this!\n",
    "5) Change the size of the GNN - The base `GCN` GNN has a hidden dimension of 64 and an output dimension of 64. Both of these can be adjusted to provide the model with more *power*. The word *power* basically means the size of the models brain or ability to learn. Increasing both of these will however increase the computational cost and subsequently make training a bit slower. A rule of thumb too is to have the output dimension equal to or less than the hidden dimension. If you read any literature after this, if you see something like *project down* or *projection layer*, the authors are typically referring to an output dimension that is smaller than the hidden dimension. The reason behind this are varied but the usually reason is computational efficiency. Very large models have hidden dimensions that make working with the output representations very computationally expensive. They train *projection* layers to make the representations smaller and more useful to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
